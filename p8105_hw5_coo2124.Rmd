---
title: "p8105_hw5_coo2124"
author: "Christiana Odewumi"
output: github_document
---

# Load necessary libraries 
```{r}
library(tidyverse)    
library(broom)        
library(purrr)
library(rvest)

set.seed(1)

knitr::opts_chunk$set(
        echo = TRUE,
        warning = FALSE,
        fig.width = 6,
        fig.asp = .6,
        out.width = "90%"
)

theme_set (theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```


## problem 1

Function to simulate birthdays and checks whether there are duplicate birthdays in the group
```{r}
simulate_shared_birthday = function(n) {
  birthdays = sample(1:365, n, replace = TRUE)
  has_duplicate = any(duplicated(birthdays))
}
```


Run this function 10,000 times for each group size between 2 and 50.
```{r}
compute_duplicate_probability <- function(n) {
  simulations <- map_lgl(1:10000, ~simulate_shared_birthday(n))
  prob <- mean(simulations)
  
  tibble(
    group_size = n,
    prob_duplicate = prob
  )
}

result_final <- map_dfr(2:50, compute_duplicate_probability)
result_final
```


Make a plot showing the probability as a function of group size, and comment on your results.
```{r}
ggplot(result_final, aes(x = group_size, y = prob_duplicate)) +
  geom_line() +
  geom_point() +
  labs(
    title = "Probability of People Sharing a Birthday",
    x = "Group Size",
    y = "Probability"
  ) +
  theme_minimal()
```

comment 
As the group size (n) increases, the probability of at least two people sharing a birthday rises rapidly, surpassing 50% with just 23 people. By a group of 50, the probability is nearly 100%, making a shared birthday almost certain. The plot highlights a nonlinear relationship, with a sharp increase for smaller groups that gradually levels off as the probability approaches 1, showing diminishing returns beyond 30 people.


## problem 2
```{r}

simulate_t_test <- function(mu, n = 30, sigma = 5) {
  data <- rnorm(n, mean = mu, sd = sigma)
  
  t_test_result <- t.test(data, mu = 0) %>% 
    broom::tidy()
  
  tibble(
    mu_hat = t_test_result$estimate,
    p_value = t_test_result$p.value
  )
}

simulate_for_mu = function(mu, n = 30, sigma = 5, simulations = 5000) {
  results = map_dfr(1:simulations, ~ simulate_t_test(mu, n, sigma))
  
  power = mean(results$p_value < 0.05)
  avg_mu = mean(results$mu_hat)
  avg_mu_rejected = mean(results$mu_hat[results$p_value < 0.05], na.rm = TRUE)
  
  tibble(
    true_mu = mu,
    power = power,
    avg_mu = avg_mu,
    avg_mu_rejected = avg_mu_rejected
  )
}

mu_values = c(1,2,3,4,5,6)
simulation_results <- map_dfr(mu_values, simulate_for_mu)

simulation_results
```


```{r}
ggplot(simulation_results, aes(x = true_mu, y = power)) +
  geom_line(color = "pink") +
  geom_point(color = "purple") +
  labs(
    title = "Power of the Test vs. True Mu",
    x = "True Value of Mu",
    y = "Power"
  ) +
  theme_minimal()
```

comments
The plot shows that as the true value of mu increases, the power of the test rises sharply. For smaller mu, the power is low, but it quickly approaches 1 for larger mu, indicating a higher likelihood of correctly rejecting the null hypothesis as the effect size grows.


```{r}
ggplot(simulation_results, aes(x = true_mu)) +
  geom_line(aes(y = avg_mu), color = "green", linetype = "solid", size = 1) +
  geom_line(aes(y = avg_mu_rejected), color = "orange", linetype = "solid", size = 1) +
  geom_point(aes(y = avg_mu), color = "green") +
  geom_point(aes(y = avg_mu_rejected), color = "orange") +
  labs(
    title = "Average Estimate of Mu vs. True Mu",
    x = "True Value of Mu",
    y = "Average Estimate"
  ) +
  theme_minimal()
```

comments
The sample average of 𝜇̂ across tests where the null hypothesis was rejected is not approximately equal to the true value of𝜇. This is due to selection bias: tests that reject the null (p<0.05) are more likely to come from samples where 𝜇̂deviates significantly from 0, leading to inflated estimates. This is evident in the plot, where the orange line representing the average of 𝜇̂for rejected samples consistently lies above the true value of𝜇In contrast, the green line, which shows the overall average of 𝜇̂ across all samples, aligns closely with the true value, demonstrating that the estimation process is unbiased when considering all data. Thus, focusing only on rejected samples results in biased, upwardly skewed estimates that do not accurately reflect the true mean.
  
  

## problem 3
```{r}

```




